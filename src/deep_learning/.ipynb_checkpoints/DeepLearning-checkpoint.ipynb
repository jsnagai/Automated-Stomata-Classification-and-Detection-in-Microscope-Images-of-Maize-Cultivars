{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "ERROR (theano.gpuarray): pygpu was configured but could not be imported or is too old (version 0.7 or higher required)\n",
      "NoneType\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = 'theano'\n",
    "os.environ['THEANO_FLAGS'] = \"device=cuda,force_device=True,floatX=float32\"\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.optimizers import SGD\n",
    "np.random.seed(123)  # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imagens de EstÃ´matos e Erros\n",
    "estomatos_treino = []\n",
    "erros_treino = []\n",
    "\n",
    "estomatos_teste = []\n",
    "erros_teste = []\n",
    "\n",
    "dir_estomatos_treino = os.listdir(\"TREINO/stoma/\")\n",
    "dir_erros_treino = os.listdir(\"TREINO/erro/\")\n",
    "dir_estomatos_teste = os.listdir(\"TESTE/stoma/\")\n",
    "dir_erros_teste = os.listdir(\"TESTE/erro/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir1_treino = \"TREINO/stoma/\"\n",
    "dir2_treino = \"TREINO/erro/\"\n",
    "dir1_teste = \"TESTE/stoma/\"\n",
    "dir2_teste = \"TESTE/erro/\"\n",
    "\n",
    "\n",
    "for aux in dir_estomatos_treino:\n",
    "    estomatos_treino.append(cv2.imread(dir1_treino + aux))\n",
    "    \n",
    "for aux in dir_erros_treino:\n",
    "    erros_treino.append(cv2.imread(dir2_treino + aux))\n",
    "    \n",
    "for aux in dir_estomatos_teste:\n",
    "    estomatos_teste.append(cv2.imread(dir1_teste + aux))\n",
    "\n",
    "for aux in dir_erros_teste:\n",
    "    erros_teste.append(cv2.imread(dir2_teste + aux))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estomatos_treino = np.array(estomatos_treino)\n",
    "erros_treino = np.array(erros_treino)\n",
    "estomatos_teste = np.array(estomatos_teste)\n",
    "erros_teste = np.array(erros_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estomatos_treino = estomatos_treino.reshape(estomatos_treino.shape[0], 3,151,258)\n",
    "erros_treino = erros_treino.reshape(erros_treino.shape[0], 3,151,258)\n",
    "estomatos_teste = estomatos_teste.reshape(estomatos_teste.shape[0], 3,151,258)\n",
    "erros_teste = erros_teste.reshape(erros_teste.shape[0], 3,151,258)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(estomatos_treino.shape, erros_treino.shape, estomatos_teste.shape, erros_teste.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estomatos_treino = estomatos_treino.astype('float32')\n",
    "estomatos_treino /=255\n",
    "erros_treino = erros_treino.astype('float32')\n",
    "erros_treino /=255\n",
    "estomatos_teste = estomatos_teste.astype('float32')\n",
    "estomatos_teste /=255\n",
    "erros_teste = erros_teste.astype('float32')\n",
    "erros_teste /=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_treino = np.array([1]*370+[0]*370)\n",
    "y_teste = np.array([1]*130+[0]*130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_treino = np_utils.to_categorical([1]*370+[0]*370)\n",
    "y_teste = np_utils.to_categorical([1]*130+[0]*130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(3,151,258)))\n",
    "model.add(Convolution2D(32, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(384,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((estomatos_treino, erros_treino), axis=0)\n",
    "model.fit(X_train, y_treino, \n",
    "          batch_size=32, nb_epoch=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_teste = np.concatenate((estomatos_teste, erros_teste), axis=0)\n",
    "score = model.evaluate(X_teste, y_teste, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(3,151,258)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_treino, batch_size=32, epochs=10,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_teste, y_teste, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model.add(Conv2D(32, (1, 1), activation='relu', input_shape=(3,151,258)))\n",
    "model.add(Conv2D(32, (1, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (1, 1), activation='relu'))\n",
    "model.add(Conv2D(64, (1, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_treino, batch_size=32, epochs=10,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_teste, y_teste, batch_size=32)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model.add(Conv2D(32, (1, 1), activation='relu', input_shape=(3,151,258)))\n",
    "model.add(Conv2D(32, (1, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (1, 1), activation='relu'))\n",
    "model.add(Conv2D(64, (1, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd,metrics=['accuracy'])\n",
    "#model.compile(optimizer='rmsprop',\n",
    "#              loss='binary_crossentropy',\n",
    "#              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_treino, batch_size=32, epochs=10,verbose=1)\n",
    "score = model.evaluate(X_teste, y_teste, batch_size=32)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model.add(Conv2D(32, (1, 1), activation='relu', input_shape=(3,151,258)))\n",
    "model.add(Conv2D(32, (1, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (1, 1), activation='relu'))\n",
    "model.add(Conv2D(64, (1, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_treino, batch_size=32, epochs=10,verbose=1)\n",
    "score = model.evaluate(X_teste, y_teste, batch_size=32)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model.add(Conv2D(32, (1, 1), activation='sigmoid', input_shape=(3,151,258)))\n",
    "model.add(Conv2D(32, (1, 1), activation='sigmoid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (1, 1), activation='sigmoid'))\n",
    "model.add(Conv2D(64, (1, 1), activation='sigmoid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd,metrics=['accuracy'])\n",
    "#model.compile(optimizer='rmsprop',\n",
    "#              loss='binary_crossentropy',\n",
    "#              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_treino, batch_size=50, epochs=10,verbose=1)\n",
    "score = model.evaluate(X_teste, y_teste, batch_size=50)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model.add(Conv2D(32, (1, 1), activation='relu', input_shape=(3,151,258)))\n",
    "model.add(Conv2D(32, (1, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(50, 50)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (1, 1), activation='relu'))\n",
    "model.add(Conv2D(64, (1, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(50, 50)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd,metrics=['accuracy'])\n",
    "#model.compile(optimizer='rmsprop',\n",
    "#              loss='binary_crossentropy',\n",
    "#              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_treino, batch_size=50, epochs=10,verbose=1)\n",
    "score = model.evaluate(X_teste, y_teste, batch_size=50)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model.add(Conv2D(32, (1, 1), activation='relu', input_shape=(3,151,258)))\n",
    "model.add(Conv2D(32, (1, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (1, 1), activation='relu'))\n",
    "model.add(Conv2D(64, (1, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_treino, batch_size=32, epochs=10,verbose=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_teste, y_teste, batch_size=50)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_shuffled = []\n",
    "y_train_shuffled = np_utils.to_categorical([1,0]*len(estomatos_treino))\n",
    "for i in range(len(estomatos_treino)):\n",
    "    train_shuffled.append(estomatos_treino[i])\n",
    "    train_shuffled.append(erros_treino[i])\n",
    "train_shuffled = np.array(train_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_shuffled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(3,151,258)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))#Retirando (2,2)\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd,metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_shuffled, y_train_shuffled, batch_size=32, epochs=10,verbose=1)\n",
    "score = model.evaluate(X_teste, y_teste, batch_size=32)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
